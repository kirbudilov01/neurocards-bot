#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è "–≤–æ—Å–∫—Ä–µ—à–µ–Ω–∏—è" –∑–∞–≤–∏—Å—à–∏—Ö –∑–∞–¥–∞—á
- –ó–∞–¥–∞—á–∏ –≤ –ë–î: processing, –Ω–æ –≤–æ—Ä–∫–µ—Ä —É–ø–∞–ª
- –ó–∞–¥–∞—á–∏ –≤ Redis: failed/started, –Ω–æ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω—ã
"""
import asyncio
import os
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from app.db_adapter import get_pool, close_db_pool
from app.services.redis_queue import get_redis
from rq.job import Job
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("üîç Checking for stuck jobs...\n")
    
    pool = await get_pool()
    redis = get_redis()
    
    # –ù–∞–π—Ç–∏ –∑–∞–¥–∞—á–∏ –≤ processing > 1 —á–∞—Å–∞
    async with pool.acquire() as conn:
        stuck_jobs = await conn.fetch(
            """
            SELECT id, tg_user_id, status, created_at, started_at
            FROM jobs
            WHERE status IN ('processing', 'queued')
              AND created_at < NOW() - INTERVAL '1 hour'
            ORDER BY created_at
            """
        )
    
    if not stuck_jobs:
        logger.info("‚úÖ No stuck jobs found")
        await close_db_pool()
        return
    
    logger.info(f"Found {len(stuck_jobs)} stuck jobs\n")
    
    for job_row in stuck_jobs:
        job_id = str(job_row['id'])
        tg_user_id = job_row['tg_user_id']
        status = job_row['status']
        
        logger.info(f"üìã Job {job_id[:8]}... (user {tg_user_id}, status: {status})")
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å –≤ Redis
        try:
            rq_job = Job.fetch(job_id, connection=redis)
            redis_status = rq_job.get_status()
            logger.info(f"   Redis status: {redis_status}")
            
            if redis_status == 'failed':
                # –ó–∞–¥–∞—á–∞ failed –≤ Redis - –ø–æ–º–µ—Ç–∏—Ç—å failed –≤ –ë–î
                async with pool.acquire() as conn:
                    await conn.execute(
                        """
                        UPDATE jobs
                        SET status = 'failed',
                            error = 'Worker crashed during processing',
                            finished_at = NOW()
                        WHERE id = $1
                        """,
                        job_id
                    )
                
                # –í–µ—Ä–Ω—É—Ç—å –∫—Ä–µ–¥–∏—Ç
                async with pool.acquire() as conn:
                    await conn.execute(
                        """
                        UPDATE users
                        SET credits = credits + 1,
                            updated_at = NOW()
                        WHERE tg_user_id = $1
                        """,
                        tg_user_id
                    )
                
                logger.info(f"   ‚úÖ Marked as failed, refunded 1 credit")
                
        except Exception as e:
            logger.warning(f"   ‚ö†Ô∏è Job not found in Redis: {e}")
            
            # –ó–∞–¥–∞—á–∏ –Ω–µ—Ç –≤ Redis –≤–æ–æ–±—â–µ - –∑–Ω–∞—á–∏—Ç queued, –Ω–æ –Ω–µ –Ω–∞—á–∞—Ç–∞
            if status == 'queued':
                # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–µ—Ä–µ—Å—Ç–∞–≤–∏—Ç—å –≤ –æ—á–µ—Ä–µ–¥—å
                from app.services.generation import start_generation
                
                async with pool.acquire() as conn:
                    job_data = await conn.fetchrow(
                        """
                        SELECT j.*, u.tg_user_id
                        FROM jobs j
                        JOIN users u ON j.user_id = u.id
                        WHERE j.id = $1
                        """,
                        job_id
                    )
                
                if job_data:
                    logger.info(f"   üîÑ Re-enqueueing job...")
                    
                    # –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—É—é –∑–∞–ø–∏—Å—å
                    async with pool.acquire() as conn:
                        await conn.execute("DELETE FROM jobs WHERE id = $1", job_id)
                    
                    # –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é (–±—É–¥–µ—Ç –Ω–æ–≤—ã–π job_id, –Ω–æ —Ç–µ –∂–µ –¥–∞–Ω–Ω—ã–µ)
                    try:
                        import json
                        product_info = job_data['product_info']
                        if isinstance(product_info, str):
                            product_info = json.loads(product_info)
                        
                        from app.services.generation import start_generation
                        # –ù–ï –≤—ã–∑—ã–≤–∞–µ–º start_generation - —ç—Ç–æ —Å–Ω–∏–º–µ—Ç –µ—â–µ –∫—Ä–µ–¥–∏—Ç!
                        # –ü—Ä–æ—Å—Ç–æ –ø–æ–º–µ—á–∞–µ–º failed –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫—Ä–µ–¥–∏—Ç
                        
                        async with pool.acquire() as conn:
                            await conn.execute(
                                """
                                UPDATE jobs
                                SET status = 'failed',
                                    error = 'Job stuck in queue, worker never picked it up',
                                    finished_at = NOW()
                                WHERE id = $1
                                """,
                                job_id
                            )
                            
                            await conn.execute(
                                """
                                UPDATE users
                                SET credits = credits + 1,
                                    updated_at = NOW()
                                WHERE tg_user_id = $1
                                """,
                                tg_user_id
                            )
                        
                        logger.info(f"   ‚úÖ Marked as failed, refunded 1 credit")
                        
                    except Exception as restart_error:
                        logger.error(f"   ‚ùå Failed to restart: {restart_error}")
    
    logger.info(f"\n‚úÖ Processed {len(stuck_jobs)} stuck jobs")
    await close_db_pool()


if __name__ == "__main__":
    asyncio.run(main())
